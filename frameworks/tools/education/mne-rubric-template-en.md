# M&E Rubric Template

**Purpose**: Provides a customizable rubric to track learning outcomes (e.g., systems thinking proficiency, empathy) and system health metrics (e.g., equity index, regenerative impact), as outlined in the framework’s monitoring and evaluation (M&E) system ([Section 5](/frameworks/docs/implementation/education#05-monitoring-evaluation)). This tool ensures accountability, equity, and continuous improvement, aligning with SDG 4 (Quality Education) and SDG 10 (Reduced Inequalities).

**Usage**:
- **Who**: Educators, community leaders, youth councils, and M&E coordinators evaluating framework pilots or scaled implementations.
- **How**: Use the rubric to assess quantitative and qualitative metrics, disaggregate data for marginalized groups, and inform iterative adjustments.
- **When**: During quarterly reviews, annual evaluations, or real-time feedback cycles ([Section 5.1](/frameworks/docs/implementation/education#05-monitoring-evaluation), [Section 5.7](/frameworks/docs/implementation/education#05-monitoring-evaluation)), as part of pilot phases ([Section 4.4](/frameworks/docs/implementation/education#04-implementation-strategies)).
- **Formats**: Editable Word document, PDF, and markdown, available in 10+ languages, with accessible versions (e.g., audio, braille, oral formats).

**Equity Safeguards**:
- Disaggregates data by gender, ethnicity, disability, and marginalized status (LGBTQ+, Indigenous, neurodiverse, disabled, caste-oppressed, refugees) to address disparities.
- Multilingual and low-tech formats (e.g., paper rubrics, oral assessments) ensure accessibility in low-connectivity or low-literacy regions.
- Community-led validation ensures metrics reflect local priorities and cultural contexts ([Section 5.5](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
- Anonymous data collection protects vulnerable participants in sensitive contexts (e.g., authoritarian regions).

## M&E Rubric Template

### Section 1: Learning Outcomes
**Purpose**: Measures individual and collective learner progress in cognitive, emotional, and ethical domains, reflecting the framework’s holistic goals ([Section 5.2](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
**Instructions**:
- Assess each competency using a 1–5 scale (1 = Emerging, 5 = Advanced).
- Collect data via educator evaluations, peer reviews, self-assessments, or alternative methods (e.g., oral portfolios for neurodiverse learners).
- Disaggregate by marginalized groups to track equity.
- Target: 80% proficiency for cognitive, 75% improvement for emotional, 50% project adoption for ethical.

**Rubric**:

| **Competency** | **Description** | **1 (Emerging)** | **3 (Proficient)** | **5 (Advanced)** | **Data Source** | **Equity Notes** |
|----------------|-----------------|------------------|-------------------|-----------------|----------------|------------------|
| Systems Thinking ([Section 3.2](/frameworks/docs/implementation/education#03-structural-components)) | Ability to map and intervene in complex systems | Identifies basic system elements | Maps systems with multiple connections | Designs interventions with measurable impact | Competency rubric, project portfolios | Oral assessments for non-literate learners |
| Empathy ([Section 3.2](/frameworks/docs/implementation/education#03-structural-components)) | Perspective-taking and emotional resilience | Recognizes others’ emotions | Demonstrates perspective-taking in group work | Leads inclusive solutions with empathy | Self-reported surveys, peer evaluations | Anonymous surveys for LGBTQ+ safety |
| Global Citizenship ([Section 3.4](/frameworks/docs/implementation/education#03-structural-components)) | Engagement in ethical, community-led initiatives | Participates in projects | Proposes community projects | Leads adopted policy or project (e.g., climate initiative) | Project counts, council reports | Prioritize refugee, caste-oppressed voices |

**Customization**:
- Add local competencies (e.g., cultural preservation for Indigenous learners).
- Adjust scale or criteria to align with regional education standards ([Section 4.1](/frameworks/docs/implementation/education#04-implementation-strategies)).

### Section 2: System Health Metrics
**Purpose**: Evaluates the framework’s operational integrity, equity, and regenerative impact across learning hubs ([Section 5.3](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
**Instructions**:
- Measure each metric using quantitative targets and qualitative feedback.
- Use audits, surveys, and community forums to collect data, ensuring 50% marginalized representation in oversight ([Section 5.5](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
- Disaggregate by region and demographic to address inequities.
- Target: 90% equity index, 100+ regenerative projects annually, 70% participation.

**Rubric**:

| **Metric** | **Description** | **Target** | **Measurement Method** | **Equity Notes** |
|------------|-----------------|------------|-----------------------|------------------|
| Equity Index ([Section 5.3](/frameworks/docs/implementation/education#05-monitoring-evaluation)) | Diversity in hub governance and participation | 90% of hubs meet diversity targets | Demographic audits, community surveys | Prioritize Indigenous, refugee representation |
| Regenerative Impact ([Section 3.3](/frameworks/docs/implementation/education#03-structural-components)) | Community-led restoration projects | 100+ projects annually (e.g., hectares restored, carbon sequestered) | Project counts, environmental data | Indigenous-led validation of outcomes |
| Participation ([Section 5.3](/frameworks/docs/implementation/education#05-monitoring-evaluation)) | Learner and community engagement | 70% active participation in councils/projects | Attendance logs, feedback surveys | Accessible formats for disabled learners |

**Customization**:
- Add local metrics (e.g., water quality improvement in coastal regions).
- Adjust targets based on pilot scale (e.g., 10 projects for micro-pilots).

### Section 3: Qualitative Feedback
**Purpose**: Captures narrative and experiential impacts to complement quantitative data, ensuring holistic evaluation ([Section 5.6](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
**Instructions**:
- Collect stories, journals, or focus group insights from learners, educators, and communities.
- Use open-ended prompts to elicit nuanced impacts (e.g., personal growth, community cohesion).
- Ensure anonymity for vulnerable groups and accessibility for non-literate participants.
- Integrate findings into global dashboard ([Section 5.8](/frameworks/docs/implementation/education#05-monitoring-evaluation)) and youth stories ([Section 7.2.2](/frameworks/docs/implementation/education#07-visual-multimedia)).

**Prompts**:
- Learners: “How has this project or curriculum changed your perspective or actions?”
- Educators: “What shifts have you observed in learner engagement or community impact?”
- Community: “How has this initiative strengthened our ecosystem or cultural pride?”

**Customization**:
- Add region-specific prompts (e.g., “How did restoring our river impact our traditions?”).
- Use visual or oral formats for neurodiverse or non-literate participants.

### Section 4: Data Collection and Reporting
**Purpose**: Outlines methods for gathering, analyzing, and sharing M&E data, ensuring transparency and actionability ([Section 5.1](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
**Instructions**:
- **Frequency**: Quarterly reviews, annual evaluations, and real-time feedback via mobile apps or paper forms ([Section 5.7](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
- **Methods**:
  - Quantitative: Surveys, rubrics, project trackers, and demographic audits.
  - Qualitative: Narrative stories, focus groups, and community forums.
- **Disaggregation**: By gender, ethnicity, disability, and marginalized status to track equity gaps.
- **Reporting**: Share results via community boards, digital platforms, and international reports ([Section 5.10](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
- **Adaptation**: Use predictive analytics to adjust strategies based on data trends ([Section 5.9](/frameworks/docs/implementation/education#05-monitoring-evaluation)).

**Customization**:
- Specify local data collection tools (e.g., community radio for feedback in rural areas).
- Adapt reporting formats to stakeholder needs (e.g., visual summaries for youth).

## Instructions for Use
1. **Adapt Rubric**: Customize competencies, metrics, and prompts to reflect local priorities and cultural contexts, engaging community boards ([Section 5.5](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
2. **Train Evaluators**: Provide 10-hour training for educators and youth on rubric use, emphasizing equity and accessibility ([Section 3.8](/frameworks/docs/implementation/education#03-structural-components)).
3. **Collect Data**: Use mixed methods (surveys, portfolios, stories) with accessible formats, ensuring marginalized group inclusion ([Section 5.1](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
4. **Analyze and Report**: Disaggregate data, validate with communities, and share via global dashboard or forums ([Section 5.8](/frameworks/docs/implementation/education#05-monitoring-evaluation), [Section 5.10](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
5. **Iterate**: Adjust curricula, projects, or strategies based on findings, using real-time feedback loops ([Section 5.7](/frameworks/docs/implementation/education#05-monitoring-evaluation)).
6. **Share Stories**: Integrate qualitative insights into multimedia assets ([Section 7.2.2](/frameworks/docs/implementation/education#07-visual-multimedia)) to inspire stakeholders.

## Example Use
In Kenya, this rubric was used to evaluate a regenerative project pilot, tracking 80% systems thinking proficiency among 500 learners and a 95% equity index across 20 hubs. Narrative feedback highlighted increased community pride, informing curriculum tweaks that boosted engagement by 35% ([Section 8.3](/frameworks/docs/implementation/education#08-case-models)).

## Cross-References
- M&E Framework ([Section 5](/frameworks/docs/implementation/education#05-monitoring-evaluation))
- Learning Outcomes ([Section 5.2](/frameworks/docs/implementation/education#05-monitoring-evaluation))
- System Health Metrics ([Section 5.3](/frameworks/docs/implementation/education#05-monitoring-evaluation))
- Qualitative M&E ([Section 5.6](/frameworks/docs/implementation/education#05-monitoring-evaluation))
- Global Climate Curriculum Case Model ([Section 8.3](/frameworks/docs/implementation/education#08-case-models))
- Regenerative Project Guide ([Section 10.1](/frameworks/docs/implementation/education#10-appendices))

## Download
Available at [framework website](https://www.globalgovernanceframework.org/frameworks/docs/implementation/education) as PDF, Word, markdown, and accessible formats (audio, braille, oral). Contact [globalgovernanceframework@gmail.com] for translation requests or support.
