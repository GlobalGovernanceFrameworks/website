# Failure Analysis Report Template: Digital Commons Framework

**Estimated Reading Time**: 8 minutes

**Purpose**: This template provides a structured format for documenting, analyzing, and learning from failures, challenges, and setbacks encountered while implementing the *Digital Commons Framework*. By transforming failures into learning opportunities, it enables continuous improvement across pilot nodes, Regional Digital Hubs, and the Global Council. The template fosters a culture of transparency, resilience, and adaptive evolution aligned with the framework's Core Principles. Applicable to technical failures, governance breakdowns, and social challenges, it helps communities build more robust and effective digital commons through systematic reflection and evidence-based adaptation.

## Overview
The Failure Analysis Report Template transforms setbacks into stepping stones for improvement, recognizing that challenges are valuable learning opportunities when systematically analyzed. This tool builds on historical commons practices where community reflection on resource management failures led to more sustainable systems, as seen in Japanese fishing villages' adaptive management and the Iroquois Confederacy's governance evolution.

This template is designed for various needs:
- **Node Facilitators**: Document and learn from local implementation challenges
- **Regional Hub Coordinators**: Identify patterns across multiple nodes
- **Technical Teams**: Analyze infrastructure or software failures
- **Governance Participants**: Review decision-making and policy shortcomings
- **Global Council Members**: Synthesize insights for framework evolution

When effectively used, failure analysis contributes to:
- **Resilience**: Building stronger systems that withstand challenges
- **Knowledge Transfer**: Preventing repeated mistakes across communities
- **Innovation**: Sparking creative solutions to persistent problems
- **Transparency**: Fostering honest assessment and accountability
- **Community Trust**: Demonstrating commitment to improvement

By transforming failures from sources of shame to opportunities for growth, this template supports the framework's commitment to adaptive evolution, ensuring digital commons governance continues to improve through evidence-based learning.

---

## How to Use This Template
This template provides a structured approach to analyzing any type of failure or challenge encountered during framework implementation.

### When to Use
Create a Failure Analysis Report for:
- **Technical Failures**: Infrastructure breakdowns, software issues, security incidents
- **Governance Challenges**: Decision-making deadlocks, process breakdowns, participation gaps
- **Implementation Setbacks**: Missed milestones, resource shortfalls, unexpected barriers
- **Community Challenges**: Participation decline, trust erosion, conflict situations
- **External Disruptions**: Regulatory changes, market shifts, environmental events

### Who Should Participate
Include diverse perspectives for comprehensive analysis:
- **Direct Observers**: People present during the incident
- **Affected Stakeholders**: Community members impacted by the failure
- **Technical Experts**: Those with relevant expertise (if applicable)
- **Governance Representatives**: Node facilitators or leadership team
- **External Perspective**: Neutral viewpoint when available

### Timeline
Complete the analysis promptly while memories are fresh:
- **Incident Documentation**: Within 1-7 days of incident
- **Full Analysis**: Within 2-3 weeks of incident
- **Action Implementation**: Begin within 1 month of report completion
- **Follow-up Evaluation**: 3-6 months after action implementation

### Documentation Methods
Adapt to your available resources:
- **Standard**: Complete digital or paper report using this template
- **Low-Resource**: Simplified documentation using key questions (see Low-Resource Guide)
- **Oral Tradition**: Structured community discussion with designated recorder
- **Visual Documentation**: Pictorial representation with simple notation

### Sharing Protocol
Maximize learning while respecting privacy:
- **Node Level**: Share full report with all node members
- **Regional Level**: Share anonymized insights with Regional Hub
- **Global Level**: Contribute key lessons to Knowledge Commons
- **Privacy Consideration**: Protect individual identities as appropriate

**Example**: Brazil's farming node experienced a data synchronization failure affecting crop recommendations. They assembled a team including farmers, technical support, and governance representatives, completed documentation within three days, conducted analysis over two weeks, and shared anonymized findings with their Regional Hub, leading to improved redundancy guidelines.

---

## Section 1: Incident Documentation
Record comprehensive details about what occurred, creating an objective foundation for analysis.

### 1.1 Basic Information
**Incident Title**: _[Brief descriptive title of the failure or challenge]_

**Date and Time**: _[When the incident occurred or was discovered]_

**Location/Context**: _[Node name, component affected, virtual/physical location]_

**Report Prepared By**: _[Names and roles of analysis team members]_

**Report Date**: _[Date this analysis was completed]_

### 1.2 Incident Description
**What Happened**: _[Detailed, factual description of the incident in chronological order]_

**Expected vs. Actual Outcome**: _[What should have happened compared to what did happen]_

**Duration**: _[How long the incident lasted or continues to last]_

**Discovery**: _[How and when the incident was discovered]_

### 1.3 Supporting Documentation
**Evidence Collected**: _[List all documentation, screenshots, logs, witness accounts]_

**Visual Documentation**: _[Include diagrams, photos, or charts if helpful]_

**Prior Indicators**: _[Were there warning signs or precursors that were missed?]_

### 1.4 Initial Response
**Immediate Actions Taken**: _[Steps taken when incident was discovered]_

**Communication**: _[How the incident was communicated to stakeholders]_

**Stabilization Measures**: _[Actions taken to prevent further harm]_

**Example**: Kenya's agricultural node documented a 48-hour mesh network failure affecting 15 villages during planting season. They recorded exact timestamps, affected components, discovery by a farmer unable to access weather data, immediate notification via SMS tree, and temporary restoration of basic service using backup solar nodes.

---

## Section 2: Impact Assessment
Evaluate the effects of the incident on stakeholders, operations, and community trust.

### 2.1 Stakeholder Impact
**Directly Affected Groups**: _[Which community members or stakeholders were impacted]_

**Nature of Impact**: _[Specific effects on each stakeholder group]_

**Scale of Impact**: _[Number of people affected, duration, severity]_

**Testimonials**: _[Direct quotes from affected stakeholders if available]_

### 2.2 Operational Impact
**System Components Affected**: _[Technical or governance systems impacted]_

**Service Disruption**: _[Functions or services that were unavailable or degraded]_

**Resource Implications**: _[Financial, time, or material resources expended]_

**Recovery Status**: _[Current state of recovery efforts]_

### 2.3 Trust and Perception Impact
**Community Feedback**: _[How the community perceived the incident and response]_

**Trust Indicators**: _[Observable changes in participation or engagement]_

**External Perception**: _[Impact on relationships with other nodes or external entities]_

**Communication Effectiveness**: _[How well the situation was communicated]_

### 2.4 Cumulative Context
**Related Past Incidents**: _[Similar previous failures or challenges]_

**Emerging Patterns**: _[Does this incident suggest a systemic issue?]_

**Compounding Factors**: _[Other conditions that worsened the impact]_

**Example**: Senegal's health data node assessed that their consent protocol failure affected 200 community members, temporarily prevented health alert access, required 120 hours of remediation work, and initially reduced trust as measured by a 30% drop in new data contributions. They identified it as the third consent-related incident in six months, suggesting a systemic issue requiring deeper intervention.

---

## Section 3: Root Cause Analysis
Dig deep to identify the underlying causes rather than just addressing symptoms.

### 3.1 Contributing Factors
**Technical Factors**: _[Hardware, software, infrastructure issues]_

**Human Factors**: _[Training, communication, decision-making, attention]_

**Process Factors**: _[Workflow, procedure, policy issues]_

**Environmental Factors**: _[External conditions, resource constraints, contextual challenges]_

### 3.2 Five Whys Analysis
_[Ask "why" at least five times to dig from symptoms to root causes]_

**Initial Problem**: _[Starting point for analysis]_

**Why #1**: _[First level cause]_ → **Why #2**: _[Deeper cause]_ → **Why #3**: _[Deeper cause]_ → **Why #4**: _[Deeper cause]_ → **Why #5**: _[Root cause]_

### 3.3 System Analysis
**Interactions**: _[How different factors combined to create the failure]_

**Missing Safeguards**: _[What controls or checks could have prevented this]_

**Structural Contributors**: _[Broader system design issues that enabled the failure]_

**Governance Implications**: _[How decision-making structures contributed]_

### 3.4 Alternative Perspectives
**Diverse Viewpoints**: _[How different stakeholders view the causes]_

**Minority Opinions**: _[Perspectives that differ from the majority view]_

**Cultural Considerations**: _[How cultural context influences interpretation]_

**Example**: Bangladesh's climate data node conducted a Five Whys analysis on their data quality failure:
1. Why did inaccurate flood predictions occur? *Sensor data was inconsistent.*
2. Why was sensor data inconsistent? *Some sensors were offline during critical periods.*
3. Why were sensors offline? *Battery failure during monsoon conditions.*
4. Why did batteries fail? *Maintenance schedule was not followed.*
5. Why wasn't maintenance followed? *Root cause: Unclear responsibility assignment between technical team and local node members.*

They identified a governance gap in defining maintenance responsibilities, a training gap in basic troubleshooting, and a design issue in battery systems for monsoon conditions.

---

## Section 4: Response Evaluation
Assess how effectively the incident was handled and what could be improved.

### 4.1 Response Timeline
**Detection to Resolution**: _[Complete timeline of response efforts]_

**Key Decision Points**: _[Critical moments and choices made]_

**Resource Allocation**: _[How people and resources were deployed]_

**Communication Flow**: _[How information was shared during response]_

### 4.2 Response Effectiveness
**What Worked Well**: _[Effective elements of the response]_

**What Could Be Improved**: _[Areas where response fell short]_

**Coordination Quality**: _[How well different actors worked together]_

**Decision Quality**: _[Whether the best choices were made with available information]_

### 4.3 Protocol Assessment
**Existing Procedures**: _[Were there protocols for this situation? Were they followed?]_

**Protocol Gaps**: _[Missing procedures or guidelines that would have helped]_

**Improvisation Quality**: _[Effectiveness of ad hoc solutions]_

**Documentation Quality**: _[How well the response was recorded]_

### 4.4 Resource Adequacy
**Available vs. Needed Resources**: _[Gap between what was available and required]_

**Critical Shortfalls**: _[Most important missing resources]_

**External Support**: _[Assistance from Regional Hub or other nodes]_

**Contingency Effectiveness**: _[How well backup systems or plans worked]_

**Example**: Germany's energy node evaluated their response to a software update failure, noting that detection took 4 hours but their decision to immediately revert to the previous version minimized disruption. They identified strong technical coordination but poor communication with users, finding their incident response protocol outdated and missing clear user communication guidelines. The node had adequate technical resources but lacked a communication coordinator role.

---

## Section 5: Lessons Learned
Synthesize key insights that can improve future operations and be shared with other nodes.

### 5.1 Primary Insights
**Key Revelations**: _[Most important discoveries from this analysis]_

**Confirmed Hypotheses**: _[Previously suspected issues now verified]_

**Surprising Findings**: _[Unexpected insights gained]_

**Historical Patterns**: _[How this connects to previous experiences]_

### 5.2 Success Factors
**Resilience Elements**: _[What prevented the situation from being worse]_

**Effective Safeguards**: _[Controls or systems that worked as intended]_

**Positive Human Factors**: _[How people contributed positively]_

**Design Strengths**: _[Aspects of system design that proved valuable]_

### 5.3 Improvement Opportunities
**Vulnerability Areas**: _[Specific weaknesses requiring attention]_

**Missing Safeguards**: _[Controls or checks that should be implemented]_

**Process Gaps**: _[Procedures needing creation or refinement]_

**Cultural Factors**: _[Community norms or practices to address]_

### 5.4 Knowledge Transfer
**Applicability to Other Nodes**: _[How these lessons might apply elsewhere]_

**Generalized Principles**: _[Broader insights beyond specific context]_

**Critical Warnings**: _[High-priority alerts for similar systems]_

**Questions Raised**: _[New questions or areas for exploration]_

**Example**: India's mobility node identified that their data privacy breach revealed vulnerabilities in their permission system but demonstrated the effectiveness of their rapid notification protocol. They recognized that their assumption of user understanding was flawed, discovered the need for simplified permission interfaces, and identified the general principle that "technical safeguards must be matched with appropriate user education" as broadly applicable to other nodes.

---

## Section 6: Recommended Actions
Translate insights into concrete improvements with clear ownership and timelines.

### 6.1 Immediate Actions
**Urgent Fixes**: _[Highest priority actions needed]_

**Responsible Parties**: _[Who will implement each action]_

**Timeline**: _[Target completion dates]_

**Success Metrics**: _[How to measure successful implementation]_

### 6.2 Systemic Improvements
**Policy Changes**: _[Governance or procedure modifications needed]_

**Training Needs**: _[New or enhanced learning opportunities]_

**Design Modifications**: _[Changes to systems or processes]_

**Resource Adjustments**: _[Different allocation of people or materials]_

### 6.3 Preventative Measures
**Early Warning System**: _[How to detect similar issues earlier]_

**Safeguards**: _[New controls to prevent recurrence]_

**Testing Protocols**: _[Validation processes to ensure effectiveness]_

**Redundancy Considerations**: _[Backup systems or processes needed]_

### 6.4 Follow-up Plan
**Review Schedule**: _[When to assess action implementation]_

**Accountability Mechanism**: _[How to ensure follow-through]_

**Communication Plan**: _[How to share progress with stakeholders]_

**Integration Path**: _[How to incorporate changes into normal operations]_

**Example**: Rwanda's node recommended three immediate actions after their voting system failure: 1) Implement SMS confirmation receipts within 7 days (Tech Coordinator), 2) Create backup paper ballot templates within 14 days (Documentation Lead), and 3) Conduct verification training at next community meeting (Facilitator). They also identified the need for a comprehensive review of all critical digital processes, development of a communication contingency plan, and establishment of a monthly audit process with success measured by 100% vote verification capability.

---

## Low-Resource Implementation Guide
Simplified approach for contexts with limited time or documentation capacity.

### Essential Questions Format
If you cannot complete the full template, answer these key questions:

1. **What happened?** *(Brief description of the incident)*
2. **Who was affected and how?** *(Impact on community)*
3. **Why did it happen?** *(Main causes)*
4. **What did we do about it?** *(Response actions)*
5. **What did we learn?** *(Key insights)*
6. **What will we do differently?** *(Main changes needed)*

### Visual Documentation Option
For communities preferring visual communication:
- Use the Failure Mapping Canvas (available in PDF)
- Draw or place symbols representing:
  - What happened (center)
  - People affected (top)
  - Root causes (left)
  - Response actions (right)
  - Future changes (bottom)

### Oral Documentation Approach
For communities with oral tradition emphasis:
- Conduct structured community dialogue using the Six Questions format
- Designate a story keeper to memorize key points
- Record summary on audio device if available
- Create memory aids (symbols, counters, etc.) for key lessons

### Minimal Written Format
One-page documentation using this structure:
```
FAILURE ANALYSIS SUMMARY
Incident: [Brief title]
Date: [When it happened]
Impact: [Who was affected, how severely]
Causes: [Main reasons it happened]
Response: [What was done about it]
Lessons: [What we learned]
Actions: [What we'll do differently]
```

**Example**: Senegal's health data node used the Six Questions format during a power outage, conducting a community circle discussion with visual mapping on cloth using colored stones to represent different aspects of their SMS system failure. They recorded key lessons via audio recording, later transcribed when power returned, focusing on the need for solar backup systems and clearer offline protocols.

---

## Case Examples
Real-world examples of effective failure analysis from different contexts:

### Mesh Network Failure (Bangladesh)
- **Incident**: Four-day connectivity loss during monsoon flooding
- **Analysis Approach**:
  - Community circle with affected villages
  - Technical review of hardware failures
  - Mapping of communication breakdown
  - Historical pattern analysis of seasonal failures
- **Key Findings**:
  - Hardware vulnerability to humidity (design flaw)
  - Lack of elevated installation in flood-prone areas
  - Missing notification system for outages
  - Insufficient battery backup capacity
- **Actions Implemented**:
  - Waterproof enclosures for all nodes
  - Established minimum height requirements
  - Created SMS alert system for outages
  - Doubled battery capacity with solar recharging
- **Outcome**: Next monsoon season experienced zero extended outages, with 95% uptime despite heavier flooding

### Data Governance Breakdown (Canada)
- **Incident**: Cultural knowledge incorrectly shared against protocols
- **Analysis Approach**:
  - Elder-led review process
  - Permission system audit
  - Process mapping of approval workflow
  - Cultural protocol documentation review
- **Key Findings**:
  - Disconnect between digital and cultural permissions
  - Lack of cultural context in metadata
  - Unclear responsibility for cultural verification
  - Training gap for technical team
- **Actions Implemented**:
  - Integrated cultural protocol tags in metadata
  - Created mandatory verification step by knowledge keepers
  - Established cultural review committee
  - Developed cross-cultural training program
- **Outcome**: Zero protocol violations in following year, with 40% increase in elder participation in digital governance

### Voting System Failure (Kenya)
- **Incident**: SMS voting system failed during critical resource allocation decision
- **Analysis Approach**:
  - Technical failure timeline reconstruction
  - User experience interviews
  - Load testing simulation
  - Backup system evaluation
- **Key Findings**:
  - System capacity insufficient for peak voting
  - Lack of error messages for failed submissions
  - No verification process for received votes
  - Missing offline backup protocol
- **Actions Implemented**:
  - Upgraded SMS gateway capacity
  - Implemented confirmation receipts
  - Created paper ballot backup system
  - Developed contingency communication plan
- **Outcome**: Subsequent votes handled 300% higher volume with 99.5% reliability, including successful failover test

### Conflict Resolution Process Failure (Brazil)
- **Incident**: Governance deadlock over resource allocation lasted two months
- **Analysis Approach**:
  - Structured interviews with all parties
  - Decision process mapping
  - Historical conflict pattern analysis
  - Governance protocol review
- **Key Findings**:
  - Unclear escalation pathway for unresolved conflicts
  - Missing neutral mediation option
  - Voting threshold too high for contentious issues
  - Inadequate representation of affected stakeholders
- **Actions Implemented**:
  - Created three-tier conflict resolution protocol
  - Established rotating mediator role
  - Implemented graduated consensus thresholds
  - Reformed stakeholder representation process
- **Outcome**: Next major conflict resolved within two weeks using new protocol, with 85% satisfaction rating from participants

---

**Resources for Implementation**:

Available at globalgovernanceframework.org/tools/digital/failure

- Full Failure Analysis Toolkit
- Five Whys Worksheet
- Visual Mapping Canvas
- Root Cause Analysis Guide
- Case Example Library

---

**Call to Action**: Resilient digital commons emerge not from avoiding failures, but from learning from them systematically. Begin documenting challenges in your node using this template, share insights with your Regional Hub, and contribute to the collective wisdom of the framework. Remember that today's failure properly analyzed becomes tomorrow's strength. Download the complete Failure Analysis Toolkit at globalgovernanceframework.org/tools/failure
